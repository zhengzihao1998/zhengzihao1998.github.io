
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="笔记">
      
      
        <meta name="author" content="zhengzihao">
      
      
        <link rel="canonical" href="https://zhengzihao1998.github.io./blog/2024/09/27/%E9%87%91%E8%9E%8D%E9%A2%86%E5%9F%9F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95/">
      
      
        <link rel="prev" href="../../19/%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E7%9B%B8%E5%85%B3/">
      
      
      
      <link rel="icon" href="../../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.34">
    
    
      
        <title>金融领域强化学习最新进展 - 个人笔记</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.35f28582.min.css">
      
        
        <link rel="stylesheet" href="../../../../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.75 1.75 0 0 1 1 7.775m1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2"/></svg>');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.5 1.75v11.5c0 .138.112.25.25.25h3.17a.75.75 0 0 1 0 1.5H2.75A1.75 1.75 0 0 1 1 13.25V1.75C1 .784 1.784 0 2.75 0h8.5C12.216 0 13 .784 13 1.75v7.736a.75.75 0 0 1-1.5 0V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25m13.274 9.537zl-4.557 4.45a.75.75 0 0 1-1.055-.008l-1.943-1.95a.75.75 0 0 1 1.062-1.058l1.419 1.425 4.026-3.932a.75.75 0 1 1 1.048 1.074M4.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5M4 7.75A.75.75 0 0 1 4.75 7h2a.75.75 0 0 1 0 1.5h-2A.75.75 0 0 1 4 7.75"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13M6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75M8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2"/></svg>');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M3.499.75a.75.75 0 0 1 1.5 0v.996C5.9 2.903 6.793 3.65 7.662 4.376l.24.202c-.036-.694.055-1.422.426-2.163C9.1.873 10.794-.045 12.622.26 14.408.558 16 1.94 16 4.25c0 1.278-.954 2.575-2.44 2.734l.146.508.065.22c.203.701.412 1.455.476 2.226.142 1.707-.4 3.03-1.487 3.898C11.714 14.671 10.27 15 8.75 15h-6a.75.75 0 0 1 0-1.5h1.376a4.5 4.5 0 0 1-.563-1.191 3.84 3.84 0 0 1-.05-2.063 4.65 4.65 0 0 1-2.025-.293.75.75 0 0 1 .525-1.406c1.357.507 2.376-.006 2.698-.318l.009-.01a.747.747 0 0 1 1.06 0 .75.75 0 0 1-.012 1.074c-.912.92-.992 1.835-.768 2.586.221.74.745 1.337 1.196 1.621H8.75c1.343 0 2.398-.296 3.074-.836.635-.507 1.036-1.31.928-2.602-.05-.603-.216-1.224-.422-1.93l-.064-.221c-.12-.407-.246-.84-.353-1.29a2.4 2.4 0 0 1-.507-.441 3.1 3.1 0 0 1-.633-1.248.75.75 0 0 1 1.455-.364c.046.185.144.436.31.627.146.168.353.305.712.305.738 0 1.25-.615 1.25-1.25 0-1.47-.95-2.315-2.123-2.51-1.172-.196-2.227.387-2.706 1.345-.46.92-.27 1.774.019 3.062l.042.19.01.05c.348.443.666.949.94 1.553a.75.75 0 1 1-1.365.62c-.553-1.217-1.32-1.94-2.3-2.768L6.7 5.527c-.814-.68-1.75-1.462-2.692-2.619a3.7 3.7 0 0 0-1.023.88c-.406.495-.663 1.036-.722 1.508.116.122.306.21.591.239.388.038.797-.06 1.032-.19a.75.75 0 0 1 .728 1.31c-.515.287-1.23.439-1.906.373-.682-.067-1.473-.38-1.879-1.193L.75 5.677V5.5c0-.984.48-1.94 1.077-2.664.46-.559 1.05-1.055 1.673-1.353z"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0"/></svg>');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13M6.92 6.085h.001a.749.749 0 1 1-1.342-.67c.169-.339.436-.701.849-.977C6.845 4.16 7.369 4 8 4a2.76 2.76 0 0 1 1.637.525c.503.377.863.965.863 1.725 0 .448-.115.83-.329 1.15-.205.307-.47.513-.692.662-.109.072-.22.138-.313.195l-.006.004a6 6 0 0 0-.26.16 1 1 0 0 0-.276.245.75.75 0 0 1-1.248-.832c.184-.264.42-.489.692-.661q.154-.1.313-.195l.007-.004c.1-.061.182-.11.258-.161a1 1 0 0 0 .277-.245C8.96 6.514 9 6.427 9 6.25a.61.61 0 0 0-.262-.525A1.27 1.27 0 0 0 8 5.5c-.369 0-.595.09-.74.187a1 1 0 0 0-.34.398M9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0M9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.344 2.343za8 8 0 0 1 11.314 11.314A8.002 8.002 0 0 1 .234 10.089a8 8 0 0 1 2.11-7.746m1.06 10.253a6.5 6.5 0 1 0 9.108-9.275 6.5 6.5 0 0 0-9.108 9.275M6.03 4.97 8 6.94l1.97-1.97a.749.749 0 0 1 1.275.326.75.75 0 0 1-.215.734L9.06 8l1.97 1.97a.749.749 0 0 1-.326 1.275.75.75 0 0 1-.734-.215L8 9.06l-1.97 1.97a.749.749 0 0 1-1.275-.326.75.75 0 0 1 .215-.734L6.94 8 4.97 6.03a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018"/></svg>');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M9.504.43a1.516 1.516 0 0 1 2.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 0 1-.871.354h-.302a1.25 1.25 0 0 1-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004zm1.047 1.074L3.286 8.571A.25.25 0 0 0 3.462 9H6.75a.75.75 0 0 1 .694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0 0 12.538 7H9.25a.75.75 0 0 1-.683-1.06l2.008-4.418.003-.006-.004-.009-.006-.006-.008-.001q-.005 0-.009.004"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.5 3.5 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327q0 .15-.025.292c.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5q-.002.615-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A5 5 0 0 1 8 16a5 5 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5 5 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.7 1.7 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06m.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.17.17 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M5 5.782V2.5h-.25a.75.75 0 0 1 0-1.5h6.5a.75.75 0 0 1 0 1.5H11v3.282l3.666 5.76C15.619 13.04 14.543 15 12.767 15H3.233c-1.776 0-2.852-1.96-1.899-3.458Zm-2.4 6.565a.75.75 0 0 0 .633 1.153h9.534a.75.75 0 0 0 .633-1.153L12.225 10.5h-8.45ZM9.5 2.5h-3V6c0 .143-.04.283-.117.403L4.73 9h6.54L9.617 6.403A.75.75 0 0 1 9.5 6Z"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1.75 2.5h10.5a.75.75 0 0 1 0 1.5H1.75a.75.75 0 0 1 0-1.5m4 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5m0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5M2.5 7.75v6a.75.75 0 0 1-1.5 0v-6a.75.75 0 0 1 1.5 0"/></svg>');}</style>


  
  
  
  
  <style>:root{--md-annotation-icon:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M22 12a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M6 13h8l-3.5 3.5 1.42 1.42L17.84 12l-5.92-5.92L10.5 7.5 14 11H6z"/></svg>');}</style>


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#recent-advances-in-reinforcement-learning-in-finance" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="个人笔记" class="md-header__button md-logo" aria-label="个人笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            个人笔记
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              金融领域强化学习最新进展
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../.." class="md-tabs__link">
        
  
    
  
  主页

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../../" class="md-tabs__link">
          
  
    
  
  笔记

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../about/" class="md-tabs__link">
        
  
    
  
  关于我

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="个人笔记" class="md-nav__button md-logo" aria-label="个人笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    个人笔记
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    主页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    笔记
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../archive/2024/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2024
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Categories
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/deep-learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deep Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/git/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Git
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/reinforcement-learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    关于我
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2.强化学习基础
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.强化学习基础">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-setupmarkov-decision-processes" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Setup:Markov decision processes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.1 Setup:Markov decision processes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#infinite-time-horizon-and-discounted-reward" class="md-nav__link">
    <span class="md-ellipsis">
      Infinite time horizon and discounted reward.
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#finite-time-horizon" class="md-nav__link">
    <span class="md-ellipsis">
      Finite time horizon.
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-mdps-and-linear-functional-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      Linear MDPs and linear functional approximation.
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content md-content--post" data-md-component="content">
    <div class="md-sidebar md-sidebar--post" data-md-component="sidebar" data-md-type="navigation">
      <div class="md-sidebar__scrollwrap">
        <div class="md-sidebar__inner md-post">
          <nav class="md-nav md-nav--primary">
            <div class="md-post__back">
              <div class="md-nav__title md-nav__container">
                <a href="../../../../" class="md-nav__link">
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
                  <span class="md-ellipsis">
                    Back to index
                  </span>
                </a>
              </div>
            </div>
            
              <div class="md-post__authors md-typeset">
                
                  <div class="md-profile md-post__profile">
                    <span class="md-author md-author--long">
                      <img src="https://avatars.githubusercontent.com/u/158252341?v=4" alt="zhengzihao">
                    </span>
                    <span class="md-profile__description">
                      <strong>
                        
                          <a href="https://github.com/zhengzihao27">zhengzihao</a>
                        
                      </strong>
                      <br>
                      Creator
                    </span>
                  </div>
                
              </div>
            
            <ul class="md-post__meta md-nav__list">
              <li class="md-nav__item md-nav__item--section">
                <div class="md-post__title">
                  <span class="md-ellipsis">
                    Metadata
                  </span>
                </div>
                <nav class="md-nav">
                  <ul class="md-nav__list">
                    <li class="md-nav__item">
                      <div class="md-nav__link">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5z"/></svg>
                        <time datetime="2024-09-27 00:00:00" class="md-ellipsis">September 27, 2024</time>
                      </div>
                    </li>
                    
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M15 13h1.5v2.82l2.44 1.41-.75 1.3L15 16.69zm4-5H5v11h4.67c-.43-.91-.67-1.93-.67-3a7 7 0 0 1 7-7c1.07 0 2.09.24 3 .67zM5 21a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1V1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v6.1c1.24 1.26 2 2.99 2 4.9a7 7 0 0 1-7 7c-1.91 0-3.64-.76-4.9-2zm11-9.85A4.85 4.85 0 0 0 11.15 16c0 2.68 2.17 4.85 4.85 4.85A4.85 4.85 0 0 0 20.85 16c0-2.68-2.17-4.85-4.85-4.85"/></svg>
                          <time datetime="2024-09-27 00:00:00" class="md-ellipsis">September 27, 2024</time>
                        </div>
                      </li>
                    
                    
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 3v15h3V3zm3 2 4 13 3-1-4-13zM5 5v13h3V5zM3 19v2h18v-2z"/></svg>
                          <span class="md-ellipsis">
                            in
                            
                              <a href="../../../../category/reinforcement-learning/">Reinforcement Learning</a></span>
                        </div>
                      </li>
                    
                    
                      
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7z"/></svg>
                          <span class="md-ellipsis">
                            
                              5 min read
                            
                          </span>
                        </div>
                      </li>
                    
                  </ul>
                </nav>
              </li>
            </ul>
          </nav>
          
        </div>
      </div>
    </div>
    <article class="md-content__inner md-typeset">
      
        


<h1 id="recent-advances-in-reinforcement-learning-in-finance">Recent advances in reinforcement learning in finance</h1>
<p>这是一篇金融领域强化学习的综述（2021）。经典的随机控制理论和其他分析方法解决金融决策问题，严重依赖模型假设。而强化学习（RL）的新发展能够用较少的模型假设，充分利用大量的金融数据，并在复杂的金融环境中改进决策。</p>
<!-- more -->

<p><strong>Autor：</strong> Ben Hambly, Renyuan Xu, Huining Yang</p>
<h2 id="2">2.强化学习基础</h2>
<h3 id="21-setupmarkov-decision-processes">2.1 Setup:Markov decision processes</h3>
<p>投资组合优化问题，通常有两类问题，一类是无限时间范围的马尔科夫决策过程(MDPs, Markov decision processes)，另一类则是有限时间范围的MDPs。前者主要研究长期投资策略，如养老金问题。而后者主要研究短期内的交易，如资产购买或清算的最优执行问题，如果目标金额没有被完全执行，则可能会在终止时间收到处罚。</p>
<h4 id="infinite-time-horizon-and-discounted-reward"><em>Infinite time horizon and discounted reward.</em></h4>
<p>首先考虑无<strong>限时间范围和折扣奖励的</strong>的<strong>离散时间MDP</strong>。</p>
<ul>
<li>状态空间 <span class="arithmatex">\(\mathcal{S}\)</span>，Markov process取值的空间</li>
<li>动作集合 <span class="arithmatex">\(\mathcal{A}\)</span>，通过在集合中采取动作影响演化</li>
<li>目的是通过选择一个策略（沿着时间的行动顺序）来优化系统的预期回报。</li>
</ul>
<p>通过定义值函数来数学的表示这一点</p>
<p>Define value function <span class="arithmatex">\(V^*\)</span> for each <span class="arithmatex">\(s \in \mathcal{S}\)</span> to be</p>
<div class="arithmatex">\[\begin{equation}
    V^{*}(s)=\sup _{\Pi} V^{\Pi}(s):=\sup _{\Pi} \mathbb{E}^{\Pi}\left[\sum_{t=0}^{\infty} \gamma^{t} r\left(s_{t}, a_{t}\right) \mid s_{0}=s\right],
\end{equation}\]</div>
<p>subject to</p>
<div class="arithmatex">\[\begin{equation}
    s_{t+1} \sim P\left(s_{t}, a_{t}\right), \quad a_{t} \sim \pi_{t}\left(s_{t}\right) .
\end{equation}\]</div>
<p>以下做一些记号上的约定：</p>
<ul>
<li><span class="arithmatex">\(\mathbb{E}^{\Pi}\)</span> 表示在策略 <span class="arithmatex">\({\Pi}\)</span> 下的期望，其中概率测度 <span class="arithmatex">\(\mathcal{P}\)</span> 描述MDP中的动态和奖励。</li>
<li>一个空间 <span class="arithmatex">\(\mathcal{X}\)</span> 的概率测度写为 <span class="arithmatex">\(\mathcal{P}(\mathcal{X})\)</span> </li>
<li>状态空间 <span class="arithmatex">\((\mathcal{S},d_\mathcal{S})\)</span> 和动作空间 <span class="arithmatex">\((\mathcal{A},d_\mathcal{A})\)</span> 都是完全可分的度量空间，包括 <span class="arithmatex">\(\mathcal{S}\)</span> 和 <span class="arithmatex">\(\mathcal{A}\)</span> 都是有限的情况，这在RL文献中常见。</li>
<li><span class="arithmatex">\(\gamma \in (0,1)\)</span> 是一个折现因子</li>
<li><span class="arithmatex">\(s_t \in \mathcal{S}\)</span>：<span class="arithmatex">\(t\)</span> 时刻的状态</li>
<li><span class="arithmatex">\(a_t \in \mathcal{A}\)</span>：<span class="arithmatex">\(t\)</span> 时刻的动作</li>
<li><span class="arithmatex">\(P: S \times \mathcal{A} \rightarrow \mathcal{P}(S)\)</span> 马尔可夫过程下的转移函数</li>
<li>记号 <span class="arithmatex">\(s_{t+1} \sim P\left(s_{t}, a_{t}\right)\)</span> 表示 <span class="arithmatex">\(s_{t+1}\)</span> 从分布 <span class="arithmatex">\(P(s_t,a_t)\in \mathcal{P}(\mathcal{S})\)</span> 中进行采样。</li>
<li>奖励 <span class="arithmatex">\(r(s,a)\)</span> 是每对<span class="arithmatex">\((s,a)\in \mathcal{S}\times \mathcal{A}\)</span> 的 <span class="arithmatex">\(\mathbb{R}\)</span> 中的一个随机变量</li>
<li>
<dl>
<dt>策略 <span class="arithmatex">\(\Pi=\left\{\pi_{t}\right\}_{t=0}^{\infty}\)</span> 是马尔可夫的，因为它只依赖于当前状态，并且可以确定性的，也可以是随机的。</dt>
<dd>
<ul>
<li>对于确定性的策略，<span class="arithmatex">\(\pi_{t}: S \rightarrow \mathcal{A}\)</span> 将当前状态 <span class="arithmatex">\(s_t\)</span> 映射到一个确定性的动作</li>
</ul>
</dd>
<dd>
<ul>
<li>对于随机策略，<span class="arithmatex">\(\pi_{t}: S \rightarrow \mathcal{P}(\mathcal{A})\)</span> 将当前状态 <span class="arithmatex">\(s_t\)</span> 映射到一个动作空间上的分布。</li>
</ul>
</dd>
<dd>
<p>&emsp;&emsp;&emsp; <span class="arithmatex">\(\pi_t(s)\in\mathcal{P}(\mathcal{A})\)</span> 表示给定状态 <span class="arithmatex">\(s\)</span> 在行动空间上的分布</p>
</dd>
<dd>
<p>&emsp;&emsp;&emsp; <span class="arithmatex">\(\pi_t(s,a)\)</span> 表示在状态 <span class="arithmatex">\(s\)</span> 采取动作 <span class="arithmatex">\(a\)</span> 的概率</p>
</dd>
</dl>
</li>
</ul>
<p>在带有无限时间范围情况下，假设奖励 <span class="arithmatex">\(r\)</span> 和转移动态 <span class="arithmatex">\(P\)</span> 是时间齐次的，
这在马尔可夫决策过程文献中是一个标准假设。
此外，如果考虑最小化成本而不是最大化奖励，问题的设置本质上是相同的。</p>
<p>著名的动态规划原则(dynamic programming principle, DPP)，
即最优策略可以通过最大化一步的奖励然后从新的状态进行最优化处理，
可以用来推导值函数(1)的贝尔曼方程</p>
<div class="arithmatex">\[\begin{equation}
    V^{*}(s)=\sup _{a \in \mathcal{A}}\left\{\mathbb{E}[r(s, a)]+\gamma \mathbb{E}_{s^{\prime} \sim P(s, a)}\left[V^{*}\left(s^{\prime}\right)\right]\right\} .
\end{equation}\]</div>
<p>可以将值函数写成</p>
<div class="arithmatex">\[V^{*}(s)=\sup _{a \in \mathcal{A}} Q^{*}(s, a) ,\]</div>
<p>其中，<span class="arithmatex">\(Q\)</span>-function，用于RL的基本量之一，定义如下</p>
<div class="arithmatex">\[\begin{equation}
    Q^{*}(s, a)=\mathbb{E}[r(s, a)]+\gamma \mathbb{E}_{s^{\prime} \sim P(s, a)}\left[V^{*}\left(s^{\prime}\right)\right],
\end{equation}\]</div>
<p>在状态 <span class="arithmatex">\(s\)</span> 下采取动作 <span class="arithmatex">\(a\)</span> 的预期奖励，后再采取最优化策略。
对于 <span class="arithmatex">\(Q\)</span>-function，也有贝尔曼方程，如下：</p>
<div class="arithmatex">\[\begin{equation}
    Q^{*}(s, a)=\mathbb{E}[r(s, a)]+\gamma \mathbb{E}_{s^{\prime} \sim P(s, a)} \sup _{a^{\prime} \in \mathcal{A}} Q^{*}\left(s^{\prime}, a^{\prime}\right) .
\end{equation}\]</div>
<p>这使我们能够从 <span class="arithmatex">\(Q(s,a)\)</span> 中提取最优（平稳）策略
<span class="arithmatex">\(\pi^*(s,a)\)</span>（如果存在的话），具体为</p>
<div class="arithmatex">\[\pi^{*}(s, a) \in \arg \max _{a \in \mathcal{A}} Q(s, a) .\]</div>
<p>此处的无限时间范围采取的折现奖励的设置，还有另一种设置是平均奖励，也被称为遍历式奖励，这种遍历式的设置通常与金融应用不相关。</p>
<h4 id="finite-time-horizon"><em>Finite time horizon.</em></h4>
<p>有限时间范围 <span class="arithmatex">\(T&lt;\infty\)</span> ，不再贴现未来的价值并且有一个终止奖励。有限时间范围的MDP问题可以表示如下：</p>
<div class="arithmatex">\[\begin{equation}
    V_{t}^{*}(s)=\sup _{\Pi} V_{t}^{\Pi}(s):=\sup _{\Pi} \mathbb{E}^{\Pi}\left[\sum_{u=t}^{T-1} r_{u}\left(s_{u}, a_{u}\right)+r_{T}\left(s_{T}\right) \Bigg| s_{t}=s\right], \forall s \in \mathcal{S},
\end{equation}\]</div>
<p>subject to</p>
<div class="arithmatex">\[\begin{equation}
    s_{u+1} \sim P_{u}\left(s_{u}, a_{u}\right), \quad a_{u} \sim \pi_{u}\left(s_{u}\right), \quad t \leq u \leq T-1.
\end{equation}\]</div>
<p>在无限时间情况的例子中，我们用 <span class="arithmatex">\(s_u\in \mathcal{S}\)</span> 和 <span class="arithmatex">\(a_u\in \mathcal{A}\)</span> 表示 agent 在时间 <span class="arithmatex">\(u\)</span> 的状态和动作。
然而，有限时间与无限时间有一点不同的是，我们允许时间依赖性的转移和奖励函数。</p>
<ul>
<li><span class="arithmatex">\(P_{u}: S \times \mathcal{A} \rightarrow \mathcal{P}(S)\)</span> 表示转移函数</li>
<li><span class="arithmatex">\(r_u(s,a)\)</span> 对每一对<span class="arithmatex">\((s,a)\in \mathcal{S}\times \mathcal{A}\)</span> 是一个实值的随机变量，<span class="arithmatex">\(t\leq u \leq T-1\)</span></li>
<li><span class="arithmatex">\(r_T(s)\)</span> 终端奖励，对所有的 <span class="arithmatex">\(s\in\mathcal{S}\)</span> 是一个实值随机变量</li>
<li><span class="arithmatex">\(\Pi=\left\{\pi_{u}\right\}_{t=0}^{T}\)</span> 马尔可夫策略可以是确定性的也可以是随机的</li>
</ul>
<p>值函数(6)对应的贝尔曼方程定义如下：</p>
<div class="arithmatex">\[\begin{equation}
    \begin{split}
        V_{t}^{*}(s) &amp;=\sup _{a \in \mathcal{A}}\left\{\mathbb{E}\left[r_{t}(s, a)\right]+\mathbb{E}_{s^{\prime} \sim P_{t}(s, a)}\left[V_{t+1}^{*}\left(s^{\prime}\right)\right]\right\}, \\
        V_{T}^{*}(s) &amp;=\mathbb{E}\left[r_{T}(s)\right]\ \ \ \ \text{(terminal condition)}
    \end{split}
\end{equation}\]</div>
<p>可以将值函数写成</p>
<div class="arithmatex">\[V_{t}^{*}(s)=\sup _{a \in \mathcal{A}} Q_{t}^{*}(s, a),\]</div>
<p>其中 <span class="arithmatex">\(Q_t^*\)</span> 函数定义如下：</p>
<div class="arithmatex">\[\begin{equation}
    Q_{t}^{*}(s, a)=\mathbb{E}\left[r_{t}(s, a)\right]+\mathbb{E}_{s^{\prime} \sim P_{t}(s, a)}\left[V_{t}^{*}\left(s^{\prime}\right)\right].
\end{equation}\]</div>
<p><span class="arithmatex">\(Q\)</span>-function 的贝尔曼方程由下式给出</p>
<div class="arithmatex">\[\begin{equation}
    \begin{split}
        Q_{t}^{*}(s, a) &amp;=\mathbb{E}\left[r_{t}(s, a)\right]+\mathbb{E}_{s^{\prime} \sim P_{t}(s, a)}\left[\sup _{a^{\prime} \in \mathcal{A}} Q_{t+1}^{*}\left(s^{\prime}, a^{\prime}\right)\right],\\
        Q_{T}^{*}(s, a) &amp;=\mathbb{E}\left[r_{T}(s)\right]\ \ \ \ \text{for all } a \in \mathcal{A}
    \end{split}
\end{equation}\]</div>
<details class="note">
<summary>Note</summary>
<p>金融时间序列数据通常是非平稳的，因此(6)和(7)式中的时间变化转移核和价格函数对于金融应用尤为重要。</p>
</details>
<p>对于一个具有有限状态和动作空间以及有限奖励 <span class="arithmatex">\(r\)</span> 的无限时间范围的马尔可夫决策过程（MDP），
一个进一步有用的观察是，只要存在最优策略，该MDP总是具有一个平稳的最优策略。</p>
<hr />
<p><strong>Theorem 2.1</strong> Theorem 6.2.7 in Puterman (2014). Assume <span class="arithmatex">\(|\mathcal{A}|&lt;\infty\)</span>, 
<span class="arithmatex">\(|\mathcal{S}|&lt;\infty\)</span>, and <span class="arithmatex">\(|r|&lt;\infty\)</span> with
probability one. For any infinite horizon discounted MDP, 
there always exists a deterministic stationary policy that is optimal.</p>
<hr />
<p>定理 2.1 意味着总是存在一个固定的策略，可以在每个时间步长执行该策略指定的操作最大化折扣奖励。
angent 不需要随时间改变策略。平均奖励的情况也有一个类似的结果，见 Theorem 8.1.2 in Puterman (2014).</p>
<p>这种洞察将寻找最优顺序决策策略问题减少到寻找最优平稳策略的问题。因此，记 <span class="arithmatex">\(\pi: S \rightarrow \mathcal{P}(\mathcal{A})\)</span> (没有时间指数) 为一个平稳策略。</p>
<h4 id="linear-mdps-and-linear-functional-approximation"><em>Linear MDPs and linear functional approximation.</em></h4>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>在线性马尔可夫决策过程（MDP）中，转移核（transition kernels）和奖励函数（reward function）被假设为相对于某些特征映射是线性的（Bradtke &amp; Barto, 1996；Melo &amp; Ribeiro, 2007）。</p>
</div>
<p>在<strong>无限时间范围的背景</strong>下，若存在 <span class="arithmatex">\(d\)</span> 个在 <span class="arithmatex">\(\mathcal{S}\)</span> 上未知(符号)测度 <span class="arithmatex">\(\mu=\left(\mu^{(1)}, \ldots, \mu^{(d)}\right)\)</span> ，以及一个未知的向量 <span class="arithmatex">\(\theta\in\mathbb{R}^d\)</span>，满足对任意的 <span class="arithmatex">\((s,a)\in \mathcal{S}\times\mathcal{A}\)</span>，有</p>
<div class="arithmatex">\[\begin{equation}
    P(\cdot \mid s, a)=\langle\phi(s, a), \mu(\cdot)\rangle, \quad r(s, a)=\langle\phi(s, a), \theta\rangle .
\end{equation}\]</div>
<p>则称该MDP为具有特征映射的特征映射 <span class="arithmatex">\(\phi:\mathcal{S}  \times \mathcal{A} \rightarrow \mathbb{R}^{d}\)</span> 的<strong>线性MDP</strong>。</p>
<p>与之相似，在<strong>有限时间背景</strong>下，若对于任意的 <span class="arithmatex">\(0\leq t \leq T\)</span>，存在 <span class="arithmatex">\(d\)</span> 个在 <span class="arithmatex">\(\mathcal{S}\)</span>上的 未知(符号)测度 <span class="arithmatex">\(\mu_{t}=\left(\mu_{t}^{(1)}, \ldots, \mu_{t}^{(d)}\right)\)</span>
以及一个未知的向量 <span class="arithmatex">\(\theta_t \in\mathbb{R}^d\)</span>，
满足对任意的 <span class="arithmatex">\((s,a)\in \mathcal{S}\times\mathcal{A}\)</span>，有</p>
<div class="arithmatex">\[\begin{equation}
    P_{t}(\cdot \mid s, a)=\left\langle\phi(s, a), \mu_{t}(\cdot)\right\rangle, \quad r_{t}(s, a)=\left\langle\phi(s, a), \theta_{t}\right\rangle
\end{equation}\]</div>
<p>则称该MDP为具有特征映射的特征映射 <span class="arithmatex">\(\phi:\mathcal{S}  \times \mathcal{A} \rightarrow \mathbb{R}^{d}\)</span> 的<strong>线性MDP</strong>。</p>
<p>通常假设这些特征(features)是 agent 已知且有界的，也就是说 <span class="arithmatex">\(\|\phi(s, a)\| \leq 1\)</span> 对所有的 <span class="arithmatex">\((s,a)\in\mathcal{S}\times\mathcal{A}\)</span>。</p>
<p>线性MDP框架与具有线性泛函逼近的RL的文献密切相关，其中的值函数假设为形式</p>
<p>For the infinite horizon case,</p>
<div class="arithmatex">\[\begin{equation}
    Q(s, a)=\langle\psi(s, a), \omega\rangle, \quad V(s)=\langle\xi(s), \eta\rangle
\end{equation}\]</div>
<p>For the finite horizon case,</p>
<div class="arithmatex">\[\begin{equation}
    Q_{t}(s, a)=\left\langle\psi(s, a), \omega_{t}\right\rangle, \quad V_{t}(s)=\left\langle\xi(s), \eta_{t}\right\rangle, \forall 0 \leq t \leq T
\end{equation}\]</div>







  
  




  



      
    </article>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2016 - 2024 Zhengzihao
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../../../../..", "features": ["navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.tabs", "navigation.expand"], "search": "../../../../../assets/javascripts/workers/search.07f07601.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.56dfad97.min.js"></script>
      
        <script src="../../../../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>